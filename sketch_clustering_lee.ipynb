{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sketch_clustering_lee.ipynb","provenance":[],"collapsed_sections":["pf-sXePhpgM1","YQeWesBYnruM","nfAN8lHBoTRB"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"pf-sXePhpgM1"},"source":["### Drive Mount"]},{"cell_type":"code","metadata":{"id":"QgPShN_M8CR6"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UTb2RneWn5dp"},"source":["### Initial Setting"]},{"cell_type":"code","metadata":{"id":"VWB08whFNasE"},"source":["!pip install efficientnet_pytorch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sJ9uHtfFWGg9"},"source":["!pip install umap-learn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T-YX_2ITJajI"},"source":["from efficientnet_pytorch import EfficientNet\n","from sklearn.cluster import KMeans\n","from sklearn.decomposition import PCA\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import f1_score\n","import os\n","import glob\n","import logging\n","import torch\n","from torch import nn\n","import pickle\n","from tqdm import tqdm # progress bar\n","from torchvision import transforms\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","from plotly.offline import plot"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XYnJ5cW0n2Zq"},"source":["# dataset path\n","data_path = \"/content/drive/MyDrive/Colab/Sketch_RNN/Sketch_RNN_Together/Dataset/Filtered_img/\"\n","# cluster_list path\n","cluster_list_path = \"/content/drive/MyDrive/Colab/Sketch_RNN/Sketch_RNN_lee/cluster_list/cluster_list_test_10.txt\"\n","# feature path\n","feat_path = \"/content/drive/MyDrive/Colab/Sketch_RNN/Sketch_RNN_lee/features/features_lee_test_10.npy\"\n","# filename path\n","filename_path = \"/content/drive/MyDrive/Colab/Sketch_RNN/Sketch_RNN_lee/filenames/filenames_lee_test_10.npy\"\n","# textfile path\n","textfile_path = \"/content/drive/MyDrive/Colab/Sketch_RNN/Sketch_RNN_lee/result.txt\"\n","# input path\n","input_data_path = \"/content/drive/MyDrive/Colab/Sketch_RNN/Sketch_RNN_Together/Dataset/input/eye/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aMgSx0PXJenF"},"source":["# make cluster_list : cluster label name files\n","cluster_list = open(cluster_list_path, 'r').read().split('\\n')\n","# make option_list\n","option_list = {}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YQeWesBYnruM"},"source":["### Save Images"]},{"cell_type":"code","metadata":{"id":"q6UQTf3pn_E8"},"source":["# save images\n","images = np.load(\"/content/drive/MyDrive/Colab/Sketch_RNN/Sketch_RNN_lee/data/test/full_numpy_bitmap_mouth.npy\")\n","os.chdir(\"/content/drive/MyDrive/Colab/Sketch_RNN/Sketch_RNN_lee/data/test\")\n","for i in range(10000):\n","  image = Image.fromarray(images[i].reshape(28, 28))\n","  image.save(str(i) + '.jpg')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nfAN8lHBoTRB"},"source":["### Rename Files"]},{"cell_type":"code","metadata":{"id":"3VNsJ--CoZ8e"},"source":["# rename files\n","def ChangeName(path, name):\n","    i = 0\n","    for filename in os.listdir(path):\n","        os.rename(path+filename, path+str(name)+'_'+str(i)+'.jpg')\n","        i += 1\n","ChangeName(data_path + \"mouth/\",\"mouth\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wLvUDAarsEIv"},"source":["### Feature Extraction"]},{"cell_type":"code","metadata":{"id":"IjCYRALgNNGN","cellView":"code"},"source":["# transform\n","tfms = transforms.Compose([transforms.Resize(224), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),]) # compose image (resize, totensor, normalize)\n","pooling = nn.AdaptiveAvgPool2d(1)\n","\n","def ExtractFeature(image, model):\n","    img = tfms(Image.open(image).convert(\"RGB\")).unsqueeze(0) # unsqueeze: vector to tensor\n","    features = model.extract_features(img)\n","    features = pooling(features)\n","    return features"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A1adKg0aJ15K"},"source":["# efficientNet\n","# feature extraction\n","# data_list = [files for files in glob.glob(data_path + '*/*.jpg')]\n","\n","# model = EfficientNet.from_pretrained('efficientnet-b0')\n","# data = {}\n","# for i, image in enumerate(tqdm(data_list)): # i for tuple data type\n","#   feat = ExtractFeature(image, model)\n","#   feat = feat.detach().numpy().reshape(-1) # detach: copy tensor without gradient\n","#   data[image] = (feat)\n","\n","# np.save(feat_path, np.array(list(data.values()))) # get a list of the features\n","#np.save(filename_path, np.array(list(data.keys()))) # get a list of the filenames"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wPCB_JlGjuCp"},"source":["input_data_list = [files for files in glob.glob(input_data_path + '*.jpg')]\n","\n","model = EfficientNet.from_pretrained('efficientnet-b0')\n","input_data = {}\n","for i, image in enumerate(tqdm(input_data_list)):\n","  input_feat = ExtractFeature(image, model)\n","  input_feat = input_feat.detach().numpy().reshape(-1)\n","  input_data[image] = (input_feat)\n","input_filenames = np.array(list(input_data.keys()))\n","input_feat = np.array(list(input_data.values()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EXSd3JgIsJF4"},"source":["### Dimension Reduction"]},{"cell_type":"code","metadata":{"id":"xabr53I0ljWk"},"source":["feat = np.load(feat_path)\n","feat_n = feat.shape[0]\n","feat = np.insert(feat,feat_n,input_feat,axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IoX_wOe6dJWz"},"source":["# PCA\n","# from sklearn.decomposition import PCA\n","# option_list['reduction'] = 'PCA'\n","# option_list['PCAComponents'] = 2\n","# pca = PCA(n_components=option_list['PCAComponents'], random_state=0)\n","# pca.fit(feat)\n","# x = pca.transform(feat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9xb1DFgBm-D9"},"source":["# TSNE\n","from sklearn.manifold import TSNE\n","option_list['reduction'] = 'TSNE'\n","option_list['TSNEComponents'] = 2\n","tsne = TSNE(n_components=option_list['TSNEComponents'], init='pca', random_state=0)\n","x = tsne.fit_transform(feat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2xDXU9hfV3d3"},"source":["# UMAP\n","# import umap\n","# option_list['reduction'] = 'UMAP'\n","# option_list['UMAPComponents'] = 2\n","# umap = umap.UMAP(n_components=option_list['UMAPComponents'], random_state=0)\n","# umap.fit(feat)\n","# x = umap.transform(feat)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M8kQROFssL5o"},"source":["### Clustering"]},{"cell_type":"code","metadata":{"id":"FvIUYj-ksubr"},"source":["def Cluster(cmd, cluster_num, input):\n","  if cmd == 'kmeans':\n","    from sklearn.cluster import KMeans\n","    option_list['clustering'] = 'KMeans'\n","    kmeans = KMeans(n_clusters = cluster_num, n_jobs = -1, random_state = 0)\n","    kmeans.fit(input)\n","    return kmeans.labels_\n","  elif cmd == 'dbscan':\n","    from sklearn.cluster import DBSCAN\n","    option_list['clustering'] = 'DBSCAN'\n","    option_list['DBEps'] = 1.3\n","    option_list['DBMinSamples'] = 2\n","    dbscan = DBSCAN(eps=option_list['DBEps'], min_samples=option_list['DBMinSamples'])\n","    dbscan.fit(input)\n","    return dbscan.labels_\n","  elif cmd == 'birch':\n","    from sklearn.cluster import Birch\n","    option_list['clustering'] = 'BIRCH'\n","    brc = Birch(n_clusters=cluster_num)\n","    brc.fit(input)\n","    return brc.labels_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kzDlzRJWLIYt"},"source":["labels = Cluster('kmeans', len(cluster_list), x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U4FI90Yxfh_B"},"source":["os.chdir(\"/content/drive/MyDrive/Colab/Sketch_RNN/Sketch_RNN_lee\")\n","fig = px.scatter(x, x=0, y=1, color = labels)\n","plot(fig)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ORK8Iodzfc6v"},"source":["### KNN"]},{"cell_type":"code","metadata":{"id":"zp5VakK7fele"},"source":["knn = KNeighborsClassifier(n_neighbors=5,algorithm='ball_tree',n_jobs=-1)\n","knn.fit(x, np.array(labels))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HmWsnNIpvIVF"},"source":["### Calculating Accuracy"]},{"cell_type":"code","metadata":{"id":"uN2ZbdDFTjIw"},"source":["def GetKey(myValue, myDict):\n","  for key, values in myDict.items():\n","    for value in values:\n","         if myValue == value:\n","             return key\n","  return \"none\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yFPSTHkadqJE"},"source":["filenames = np.load(filename_path)\n","filenames_n = filenames.shape[0]\n","filenames = np.insert(filenames,filenames_n,input_filenames,axis= 0)\n","\n","# holds the cluster id and the images { id: [images] }\n","groups = {}\n","for f, cluster in zip(filenames, labels):\n","    if cluster not in groups.keys():\n","        groups[cluster] = []\n","        groups[cluster].append(f)\n","    else:\n","        groups[cluster].append(f)\n","\n","# make cluster_dict for calculate acc\n","cluster_dict = {}\n","for cluster in groups:\n","  image_count = []\n","  image_name = []\n","  for image in groups[cluster]:\n","    image_name.append(image.split('/')[-2])\n","  for name in cluster_list:\n","    image_count.append(image_name.count(name))\n","  cluster_dict[cluster] = cluster_list[image_count.index(max(image_count))] # Select the most frequently classified label as the correct label\n","option_list['clusterDictSize'] = len(cluster_dict)\n","\n","# get accuracy\n","ans = []\n","result = []    \n","for cluster in groups:\n","    for category in groups[cluster]:\n","        ans.append(cluster_dict[cluster])\n","        result.append(category.split('/')[-2])\n","acc = str(round(f1_score(result, ans, average='micro') * 100, 2)) + '%'\n","option_list['accuracy'] = acc\n","print(acc)\n","\n","# check input answer\n","for filename in input_filenames:\n","  inputKey = GetKey(filename, groups)\n","  inputAns = filename.split('/')[-2]\n","  inputResult = cluster_dict[inputKey]\n","  if (inputAns == inputResult):\n","    print('correct!')\n","  else:\n","    print('wrong...')\n","  print('input: ' + inputAns + ', result: ' + inputResult)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vHv_H3a1fLwR"},"source":["# write the result on textfile\n","f = open(textfile_path, 'a', encoding='UTF-8')\n","for key, value in option_list.items():\n","  f.write(f'{value} ')\n","f.write(f'\\n')\n","f.close()"],"execution_count":null,"outputs":[]}]}