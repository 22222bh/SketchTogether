{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "filtered_bh.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNy9l6nkhLaGPiuwcKDi39w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/22222bh/SketchTogether/blob/haewon/filtered_bh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSSGp-AdN1hi"
      },
      "source": [
        "초기 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nwTUYKTN0SA",
        "outputId": "12b917f8-b42a-4a6e-b772-30cd6eeb68c9"
      },
      "source": [
        "!pip install efficientnet_pytorch\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.7/dist-packages (0.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_vfG8EQN1VP"
      },
      "source": [
        "from efficientnet_pytorch import EfficientNet\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "# from keras.applications.vgg16 import VGG16 \n",
        "# from keras.models import Model\n",
        "# from keras.applications.vgg16 import preprocess_input \n",
        "import os\n",
        "import logging\n",
        "import torch\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Pyjvf2NODmd"
      },
      "source": [
        "filename = 'filtered_10'\n",
        "data_path = '/content/drive/MyDrive/Sketch_RNN/Dataset/Filtered_img/'\n",
        "cluster_list_path = '/content/drive/MyDrive/Sketch_RNN/Dataset/Filtered_img/cluster_list.txt'\n",
        "feat_path = \"/content/drive/MyDrive/skku_Clustering/features_hw_\" + filename + \".npy\"\n",
        "filename_path = \"/content/drive/MyDrive/skku_Clustering/filenames_hw_\" + filename + \".npy\"\n",
        "save_path = '/content/drive/MyDrive/skku_Clustering/Result/'\n",
        "test_path = '/content/drive/MyDrive/skku_Clustering/test_set/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JETaCQloN-s7"
      },
      "source": [
        "os.chdir(data_path)\n",
        "data_list = []\n",
        "with os.scandir(data_path) as files:\n",
        "    for file in files:\n",
        "        if not file.name.endswith('.txt'):\n",
        "            data_list.append(file.name)\n",
        "\n",
        "cluster_list = open(cluster_list_path , 'r').read().split('\\n') \n",
        "\n",
        "#transform\n",
        "tfms = transforms.Compose([transforms.Resize(224), transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n",
        "\n",
        "def feature_extraction(image, model):\n",
        "    img = tfms(image.convert(\"RGB\")).unsqueeze(0)\n",
        "    features = model.extract_features(img)\n",
        "    return features\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF2O8Z0l8ALu"
      },
      "source": [
        "# Test set 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hF12WLlb7-4S",
        "outputId": "8a41d71e-d5e2-4364-a6af-3877abc426f5"
      },
      "source": [
        "cluster_list = open(cluster_list_path, 'r').read().split('\\n')\n",
        "\n",
        "s = 2000\n",
        "e = 2050\n",
        "for label in cluster_list:\n",
        "  path = test_path + label + '/'\n",
        "  print(path)\n",
        "  if os.path.isdir(path) == False:\n",
        "    os.makedirs(path)\n",
        "  os.chdir(path)\n",
        "  images = np.load('/content/drive/MyDrive/Sketch_RNN/Dataset/test/' + label + '.npy')\n",
        "  for i in range (s, e): \n",
        "    image = Image.fromarray(images[i].reshape(28, 28))\n",
        "    image.save('test_' + label + '_' + str(i - s + 1) + '.jpg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/skku_Clustering/test_set/cat/\n",
            "/content/drive/MyDrive/skku_Clustering/test_set/circle/\n",
            "/content/drive/MyDrive/skku_Clustering/test_set/cloud/\n",
            "/content/drive/MyDrive/skku_Clustering/test_set/dog/\n",
            "/content/drive/MyDrive/skku_Clustering/test_set/ear/\n",
            "/content/drive/MyDrive/skku_Clustering/test_set/eye/\n",
            "/content/drive/MyDrive/skku_Clustering/test_set/moustache/\n",
            "/content/drive/MyDrive/skku_Clustering/test_set/mouth/\n",
            "/content/drive/MyDrive/skku_Clustering/test_set/nose/\n",
            "/content/drive/MyDrive/skku_Clustering/test_set/triangle/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdWegNuUHTu-"
      },
      "source": [
        "# Clustering algorithm 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nlxINqJC5Cj"
      },
      "source": [
        "_eps = 1.3\n",
        "_ms = 2\n",
        "\n",
        "def clustering_method(cmd, cluster_num, input):\n",
        "  if cmd == 'kmeans':\n",
        "    from sklearn.cluster import KMeans\n",
        "    kmeans = KMeans(n_clusters=cluster_num, n_init = 20, n_jobs=-1, random_state = 0)\n",
        "    kmeans.fit(input)\n",
        "    return kmeans.labels_\n",
        "\n",
        "  elif cmd == 'minibatch':\n",
        "    from sklearn.cluster import MiniBatchKMeans\n",
        "    mb_kmeans = MiniBatchKMeans(n_clusters=cluster_num,random_state=0, batch_size=6)\n",
        "    mb_kmeans.fit(input)\n",
        "    return mb_kmeans.labels_\n",
        "\n",
        "  elif cmd == 'dbscan':\n",
        "    from sklearn.cluster import DBSCAN\n",
        "    dbscan = DBSCAN(eps=_eps, min_samples=_ms) # eps 1.8이면 63프로\n",
        "    dbscan.fit(input)\n",
        "    return dbscan.labels_\n",
        "  \n",
        "  elif cmd == 'optics':\n",
        "    from sklearn.cluster import OPTICS, cluster_optics_dbscan\n",
        "    optics = OPTICS(min_samples = 5)\n",
        "    optics.fit(input)\n",
        "    return optics.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "wupHmO777KFr",
        "outputId": "1d846986-841d-4448-bb12-642ce574919c"
      },
      "source": [
        "from torch import nn\n",
        "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "data = {}\n",
        "noise = 0\n",
        "correct = 0\n",
        "wrong = 0\n",
        "avg_pooling = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "os.chdir(test_path)\n",
        "test_list = []\n",
        "with os.scandir(test_path) as files:\n",
        "  for file in files:\n",
        "    if not file.name.startswith('.'):\n",
        "      test_list.append(file.name)\n",
        "\n",
        "for folder in test_list:\n",
        "  test_images = os.listdir(test_path + folder)\n",
        "  for i, image_name in enumerate(test_images):\n",
        "    # train data의 feature vector load\n",
        "    feat = np.load(feat_path)\n",
        "\n",
        "    # test data에 대하여 feature 추출\n",
        "    image = Image.open(test_path + folder +'/'+ image_name)\n",
        "    new_feat = feature_extraction(image, model)\n",
        "    new_feat = avg_pooling(new_feat)\n",
        "    new_feat = new_feat.detach().numpy().reshape(-1)\n",
        "    new_feat = new_feat.reshape(1, -1)\n",
        "\n",
        "    # 기존 feature vector에 append. \n",
        "    feat = np.append(feat, new_feat, axis = 0)\n",
        "    # print(feat.shape) # 608이 나와야 함\n",
        "\n",
        "    # 차원 축소(t-SNE)\n",
        "    tsne = TSNE(n_components=2, init='pca', random_state=0)\n",
        "    feat = tsne.fit_transform(feat)\n",
        "\n",
        "    # clustering\n",
        "    labels = clustering_method('dbscan', len(cluster_list), feat)\n",
        "\n",
        "    # 결과 보는 단계\n",
        "    filenames = np.load(filename_path)\n",
        "    filenames = np.append(filenames,image_name)\n",
        "\n",
        "    groups = {}\n",
        "    # holds the cluster id and the images { id: [images] }\n",
        "    i = 0\n",
        "    for f, cluster in zip(filenames, labels):\n",
        "        if cluster not in groups.keys():\n",
        "            groups[cluster] = []\n",
        "            groups[cluster].append(f)\n",
        "        else:\n",
        "            groups[cluster].append(f)\n",
        "\n",
        "\n",
        "    #make cluster_dict for calculate acc\n",
        "    cluster_dict = {}\n",
        "    for cluster in groups:\n",
        "      image_count = []\n",
        "      image_name = []\n",
        "      for image in groups[cluster]:\n",
        "        image_name.append(image.split('_')[0])\n",
        "      for name in cluster_list:\n",
        "        image_count.append(image_name.count(name))\n",
        "      cluster_dict[cluster] = cluster_list[image_count.index(max(image_count))]\n",
        "    \n",
        "    #Acc\n",
        "    from sklearn.metrics import f1_score\n",
        "    pred = []\n",
        "    gt = []    \n",
        "    for cluster in groups:\n",
        "        for food in groups[cluster]:\n",
        "            pred.append(cluster_dict[cluster])\n",
        "            gt.append(food.split('_')[0])\n",
        "            if food.split('_')[0] == 'test':\n",
        "              tmp = food.split('_')[1] + food.split('_')[2].split('.')[0]\n",
        "              if cluster == -1:\n",
        "                res = food.split('_')[1] + ' = ' + str(cluster)\n",
        "                noise+=1\n",
        "              else:\n",
        "                res = food.split('_')[1] + ' = ' + cluster_dict[cluster]\n",
        "                if food.split('_')[1] == cluster_dict[cluster]:\n",
        "                  correct += 1\n",
        "                else:\n",
        "                  wrong += 1\n",
        "\n",
        "    acc = str(round(f1_score(gt, pred,average='micro') * 100, 2))\n",
        "    print(tmp + ' ->  res: ' + res + '    ACC: ' + acc + '    #cluster: ' + str(len(cluster_dict)))\n",
        "    print('\\t\\t\\t', end='')\n",
        "    print(cluster_dict)\n",
        "\n",
        "print('-----result-----')\n",
        "print('total test: ', wrong + noise + correct)\n",
        "print('noise: ', noise)\n",
        "print('correct: ', correct)\n",
        "print('wrong: ', wrong)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n",
            "cat3 ->  res: cat = cat    ACC: 63.32    #cluster: 10\n",
            "\t\t\t{5: 'nose', 4: 'dog', 2: 'triangle', 8: 'moustache', 6: 'circle', 1: 'cat', 9: 'dog', 3: 'cat', 7: 'cloud', 0: 'eye'}\n",
            "cat5 ->  res: cat = ear    ACC: 66.94    #cluster: 10\n",
            "\t\t\t{1: 'nose', 8: 'ear', 4: 'dog', 9: 'circle', 2: 'cat', 3: 'cat', 5: 'cloud', 7: 'triangle', 6: 'moustache', 0: 'eye'}\n",
            "cat7 ->  res: cat = cat    ACC: 67.76    #cluster: 10\n",
            "\t\t\t{7: 'nose', 0: 'ear', 5: 'circle', 8: 'cat', 6: 'dog', 1: 'cat', 9: 'cloud', 3: 'triangle', 2: 'eye', 4: 'moustache'}\n",
            "cat8 ->  res: cat = cat    ACC: 65.46    #cluster: 10\n",
            "\t\t\t{5: 'nose', 6: 'ear', 4: 'circle', 2: 'cat', 9: 'cat', 3: 'dog', 7: 'cloud', 1: 'triangle', 8: 'moustache', 0: 'eye'}\n",
            "cat9 ->  res: cat = dog    ACC: 64.14    #cluster: 10\n",
            "\t\t\t{7: 'nose', 4: 'ear', 3: 'circle', 6: 'cat', 2: 'cat', 9: 'dog', 1: 'triangle', 5: 'cloud', 0: 'eye', 8: 'moustache'}\n",
            "cat10 ->  res: cat = cat    ACC: 66.94    #cluster: 10\n",
            "\t\t\t{5: 'nose', 1: 'ear', 3: 'dog', 4: 'circle', 0: 'cat', 6: 'cat', 7: 'cloud', 9: 'eye', 2: 'triangle', 8: 'moustache'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-fc1e6f4d6be7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# 차원 축소(t-SNE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# clustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    884\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         \"\"\"\n\u001b[0;32m--> 886\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    796\u001b[0m                           \u001b[0mX_embedded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_embedded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                           \u001b[0mneighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneighbors_nn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                           skip_num_points=skip_num_points)\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m     def _tsne(self, P, degrees_of_freedom, n_samples, X_embedded,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_tsne\u001b[0;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0mopt_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_iter_without_progress'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_without_progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m             params, kl_divergence, it = _gradient_descent(obj_func, params,\n\u001b[0;32m--> 852\u001b[0;31m                                                           **opt_args)\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;31m# Save the final number of iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_gradient_descent\u001b[0;34m(objective, p0, it, n_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compute_error'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_convergence\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_kl_divergence_bh\u001b[0;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose, compute_error, num_threads)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0mval_P\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m     \u001b[0mindptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}